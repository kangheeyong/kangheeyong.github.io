---
title: Noise Canceling Network Project 분석 및 계획
description:
categories:
 - project 1
tags:
---

2017년 당시 스마트 스피커의 문제는 노래가 나오는 중에 스마트 스피커를 부르면 인식이 잘 안 되는 문제가 있었다. 그 이유는 스마트 스피커에 녹음되는 소리는 사람 목소리와 노랫소리가 같이 들어가기 때문이다. 스마트 스피커에 노래가 나오기 때문에 마이크에 들어오는 신호에서 노래 신호를 빼면 이 문제를 해결할 수 있는 것처럼 보인다. 하지만 음원 신호가 스피커를 통해 녹음이 되면 스피커의 성능에 따라서 파형이 변하게 된다. 예를 들면 특정 주파수의 신호가 커지거나 작아진다. 그리고 다른 문제는 스마트 스피커이기 때문에 음원이 나오는 스피커와 사람의 목소리가 녹음되는 마이크의 위치는 사람과 마이크 사이의 거리보다 좁다는 거다. 즉, 이본적으로 사람의 목소리가 노랫소리보다 작게 녹음이 된다. 3차원 공간이기 때문에 음원은 거리의 세제곱의 반비례로 약해질 것이다. 따라서 어느 정도 약한 신호도 증폭을 해야 한다. 여기서 잊지 말아야 하는 것은 이때 당시 이 프로젝트의 목적은 스마트 스피커에서 노래가 어느 정도 크게 나오고 있을 때, 사람이 그 스마트 스피커를 부르면 음원이 제거되고, 사람 목소리만 남은 신호가 STT(Speech To Text) 프로그램을 거쳐서 나온 텍스트가 사람이 말한 것과 같게 나오는 게 목적이었다.






### 문제 접근 과정

#### 과거 문제 접근 방법

 ![](/assets/project_1/1.JPG)

위의 그림은 그때 당시의 문제 접근이었다. 여기서 ref는 음원 신호, s는 사람 목소리, n은 주변 환경 잡음 신호이다. 하지만 결과가 좋지 않았다.

#### 과거 문제 접근 방법의 문제점 분석
##### 하드웨어를 고려를 안함

 ![](/assets/project_1/3.JPG)

과거의 문제 접근의 문제점은 하드웨어를 고려하지 못한 부분으로 생각했다. 하드웨어를 고려하면 위와 같은 구조로 표현할 수 있다. ref신호는 기본적으로 mp3, wav파일 같은 것이다. 따라서 스피커를 지나게 되면 원래의 ref신호로 나오는 게 아니라 spk(ref) 신호로 나오게 된다. 즉, 스피커의 특성에 따라서 신호의 왜곡이 달라진다는 것이다. 또한 마이크도 있기 때문에 한 번의 왜곡이 더 생기게 된다. 따라서 스피커와 마이크의 특성을 고려해서 학습을 하면 더 좋은 성능이 나오지 않을까 추측한다.

##### 출력 및 입력 사이의 거리를 고려 안함

 ![](/assets/project_1/4.JPG)

스피커와 마이크의 거리는 하드웨어가 정해지면 일정하다. 하지만 사람과 마이크의 거리는 상황에 따라서 달라진다. 예를 들면 스마트 스피커를 거실에 설치했다고 가정하자. 하지만 거실의 크기는 집마다 다르고 다른 공간(부엌 또는 화장실 등)에서 소리를 낼 경우 거리에 따라 사람 목소리의 신호 크기가 달라질 것이다. 따라서 학습을 할 때, 이러한 정보를 알려주면 성능이 더 향상될 것이라고 생각한다.

##### 스피커 음량이 일정하지 않는 것을 고려 안 함

마이크와 스피커의 거리는 일정하지만, 스피커의 음량은 상황에 따라 다를 수 있다. 따라서 같은 ref신호를 사용해도 음량을 어떻게 하느냐에 따라서 다은 입력 상황이 만들어진다.

 ![](/assets/project_1/5.JPG)

##### 결론

위의 결론을 내기 위해서 기본적인 가정은

>"학습을 이용해서 만든 네트워크(Fully Conneted
또는 Convolution으로 이루어진 Network)는 학습을 한 내용이 입력으로 들어갔을 경우에만 좋은 성능을 낼 것이다."

위와 같다. 따라서 처음 문제 접근 방법의 문제점은 입력 데이터의 패턴은 한 가지지만 실제 환경에서의 패턴은 다양하다. 따라서 한 가지 패턴만 학습을 했기 때문에 학습한 패턴 이외의 것이 입력으로 들어갔을 경우 좋은 성능을 낼 수 없었다. 따라서 이 문제를 해결하기 위해서는 실험적인 환경과 실제 환경의 차이에 대한 인식을 먼저 한 후 문제를 다시 정의해야 한다고 생각한다.

#### 새로운 해결책
* 문제 : ref신호를 가지고 왜곡된 ref 신호를 제거할 수 있을까?
* 문제 분석 : 왜곡된 ref 신호는 스피커의 특성에 의한 결과 값일 것이다. 그리고 이 특성은 선형 시스템을 따를 것이라고 생각된다.
* 해결방법 : 만약 이 특성이 선형 시스템이라면 수식으로 만들면 된다.
* 결론 : 스피커를 모델링해서 학습할 때 임의로 스피커 특성이 반영된 음원파일을 입력 데이터로 넣어보자.

![](/assets/project_1/6.JPG)

위의 모델은 새로운 모델이다. 이전과의 차이점은 과거에는 ref신호와 마이크에 들어오는 신호를 어떤 알고리즘 이용해서 뺐었지만, 새롭게 제안된 모델은 Network 모델이 한 번에 학습을 다한다. network 구조는 Convolution layer와 skip connection으로 구성된다.

### 실험 과정

1. 기본 가정 검증(experiment_1 폴더 ) : (2018.1.17 완료)
    * 학습한 내용만 성능이 좋다는 말을 이 네트워크에 적용해보면, 한 가지 스케일로 학습 모델에 학습에 한 번도 적용되지 않은 스케일을 넣었을 경우 우리가 기대한 결과값이 안 나온다는 말이다.

2. 모델 검증 : MNIST data(experiment_2) : (2018.2.2 완료)
3. 실제 음원 녹음 환경 구성
4. 스피커 모델링 함수 설계
5. 실제 음원으로 학습 후 성능 확인

---

* [위의 실험 github](https://github.com/kangheeyong/2018-1-Deep-Learing-pc1/tree/master/Noise_Canceling_Net_project)
